{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26590b25",
   "metadata": {},
   "source": [
    "**About the Dataset:** The data includes transactions  made by European credit card users in September 2013, due of confidentiality concerns, the publishers didn't give the original features or much background on the data. It only has numerical input variables on which PCA transformation was done\n",
    "\n",
    "The dataset has a big imbalance between fraud and non-fraud cases, so we can't rely on accuracy from a confusion matrix as a metric. Instead, we'll use the Area Under the Precision-Recall Curve (AUPRC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa719242",
   "metadata": {},
   "source": [
    "Dataset : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cdb50",
   "metadata": {},
   "source": [
    "**Data Desciption**\n",
    "\n",
    "* Time: Time at which the transaction occurs\n",
    "* V1 to V28 : 28 Features (PCA)\n",
    "* Amount: The amount of the transaction.\n",
    "* Class (fraud label): A binary variable, with the value for a legitimate transaction, or the value for a fraudulent transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2668601",
   "metadata": {},
   "source": [
    "* **Objective :** Anonymized credit card transactions labeled as fraudulent or genuine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305aa17",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad086579",
   "metadata": {},
   "source": [
    "* **Importing Python Librabries**\n",
    "* **Exploratory Data Analysis**\n",
    "* **Sampling Dataset**\n",
    "* **Model Buidling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be8b87",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b941ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5ed9b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502bc956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"creditcard.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35874d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 284807\n",
      "columns: 31\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of rows and columns in the datase\n",
    "\n",
    "print(f\"rows: {df.shape[0]}\\ncolumns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559e10ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d8b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ba41a",
   "metadata": {},
   "source": [
    "* No null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d9de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Class Ratio\n",
      " 0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking for the class balance ratio\n",
    "print(df[\"Class\"].value_counts())\n",
    "print(\"\\nClass Ratio\\n\",df[\"Class\"].value_counts()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564be6b",
   "metadata": {},
   "source": [
    "* Since our goal is to detect fraud activities, it's crucial to note that the dataset is highly imbalanced. This imbalance means that our model might focus more on learning about non-fraudulent activities and less on fraudulent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e13827",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf288fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating class varibles  to understand about the statistical analysis\n",
    "Non_fraudulent = df[df[\"Class\"]==0]\n",
    "fraudulent= df[df[\"Class\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db80887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 31), (492, 31))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Non_fraudulent.shape, fraudulent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33342165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Non_fraudulent[\"Amount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3035807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent[\"Amount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51c966",
   "metadata": {},
   "source": [
    "# we can see that in Non Fraudulent and Fraudulent the means are different.\n",
    "The transac????\n",
    "but median is low so what doe this mean as inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb04584",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1faa9",
   "metadata": {},
   "source": [
    "## Method 1 : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11540de1",
   "metadata": {},
   "source": [
    "#### Performing random sampling of the non-fraudulent class to match the number of rows with the fraudulent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16926451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156961</th>\n",
       "      <td>109263.0</td>\n",
       "      <td>1.833227</td>\n",
       "      <td>0.364711</td>\n",
       "      <td>0.451166</td>\n",
       "      <td>4.091917</td>\n",
       "      <td>-0.227509</td>\n",
       "      <td>0.374196</td>\n",
       "      <td>-0.583237</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.954938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>0.485685</td>\n",
       "      <td>0.189123</td>\n",
       "      <td>-0.084402</td>\n",
       "      <td>-0.264453</td>\n",
       "      <td>-0.009945</td>\n",
       "      <td>-0.006484</td>\n",
       "      <td>-0.034535</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179147</th>\n",
       "      <td>123946.0</td>\n",
       "      <td>2.085175</td>\n",
       "      <td>0.393051</td>\n",
       "      <td>-4.508201</td>\n",
       "      <td>-0.311771</td>\n",
       "      <td>3.510117</td>\n",
       "      <td>2.453299</td>\n",
       "      <td>0.220469</td>\n",
       "      <td>0.543377</td>\n",
       "      <td>-0.100434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067217</td>\n",
       "      <td>-0.072642</td>\n",
       "      <td>-0.036584</td>\n",
       "      <td>0.529693</td>\n",
       "      <td>0.414685</td>\n",
       "      <td>0.735870</td>\n",
       "      <td>-0.058233</td>\n",
       "      <td>-0.026658</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15067</th>\n",
       "      <td>26414.0</td>\n",
       "      <td>-0.262444</td>\n",
       "      <td>-3.162121</td>\n",
       "      <td>-0.294218</td>\n",
       "      <td>-0.796267</td>\n",
       "      <td>-1.940072</td>\n",
       "      <td>-0.380838</td>\n",
       "      <td>0.388393</td>\n",
       "      <td>-0.228600</td>\n",
       "      <td>1.992874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574583</td>\n",
       "      <td>0.075166</td>\n",
       "      <td>-0.887120</td>\n",
       "      <td>-0.008395</td>\n",
       "      <td>0.270159</td>\n",
       "      <td>-0.040588</td>\n",
       "      <td>-0.102476</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>816.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>32637.0</td>\n",
       "      <td>-0.883467</td>\n",
       "      <td>-0.211395</td>\n",
       "      <td>1.359311</td>\n",
       "      <td>-1.221876</td>\n",
       "      <td>0.498644</td>\n",
       "      <td>0.080569</td>\n",
       "      <td>1.007131</td>\n",
       "      <td>-0.109152</td>\n",
       "      <td>-0.354324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099961</td>\n",
       "      <td>-0.615560</td>\n",
       "      <td>0.241685</td>\n",
       "      <td>-0.836969</td>\n",
       "      <td>-0.307358</td>\n",
       "      <td>0.594305</td>\n",
       "      <td>-0.218686</td>\n",
       "      <td>-0.112627</td>\n",
       "      <td>164.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111394</th>\n",
       "      <td>72214.0</td>\n",
       "      <td>1.075827</td>\n",
       "      <td>-0.274463</td>\n",
       "      <td>1.093012</td>\n",
       "      <td>1.532927</td>\n",
       "      <td>-0.583176</td>\n",
       "      <td>1.082587</td>\n",
       "      <td>-0.733305</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>1.189631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403918</td>\n",
       "      <td>-0.757279</td>\n",
       "      <td>0.052991</td>\n",
       "      <td>-0.332710</td>\n",
       "      <td>0.403760</td>\n",
       "      <td>-0.502030</td>\n",
       "      <td>0.081161</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222979</th>\n",
       "      <td>143204.0</td>\n",
       "      <td>2.239052</td>\n",
       "      <td>-1.468257</td>\n",
       "      <td>-0.415760</td>\n",
       "      <td>-1.651330</td>\n",
       "      <td>-1.518224</td>\n",
       "      <td>-0.328507</td>\n",
       "      <td>-1.458644</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>-1.217365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371511</td>\n",
       "      <td>-0.623488</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>-0.404534</td>\n",
       "      <td>-0.595912</td>\n",
       "      <td>-0.483846</td>\n",
       "      <td>0.034075</td>\n",
       "      <td>-0.047606</td>\n",
       "      <td>15.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67355</th>\n",
       "      <td>52491.0</td>\n",
       "      <td>1.314442</td>\n",
       "      <td>-0.765168</td>\n",
       "      <td>0.119475</td>\n",
       "      <td>-0.787712</td>\n",
       "      <td>-0.501423</td>\n",
       "      <td>0.448607</td>\n",
       "      <td>-0.723523</td>\n",
       "      <td>0.170127</td>\n",
       "      <td>-0.630945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.081010</td>\n",
       "      <td>-0.139929</td>\n",
       "      <td>-0.784148</td>\n",
       "      <td>0.550084</td>\n",
       "      <td>-0.182887</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>-0.004491</td>\n",
       "      <td>36.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166502</th>\n",
       "      <td>118117.0</td>\n",
       "      <td>0.146613</td>\n",
       "      <td>1.232617</td>\n",
       "      <td>-1.281238</td>\n",
       "      <td>-0.092007</td>\n",
       "      <td>0.962813</td>\n",
       "      <td>-0.449265</td>\n",
       "      <td>0.361553</td>\n",
       "      <td>-1.860332</td>\n",
       "      <td>0.161723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.471837</td>\n",
       "      <td>-0.374324</td>\n",
       "      <td>-0.377807</td>\n",
       "      <td>-0.846036</td>\n",
       "      <td>1.083432</td>\n",
       "      <td>0.829297</td>\n",
       "      <td>0.214370</td>\n",
       "      <td>0.285213</td>\n",
       "      <td>29.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101600</th>\n",
       "      <td>67890.0</td>\n",
       "      <td>1.197949</td>\n",
       "      <td>0.343806</td>\n",
       "      <td>0.287047</td>\n",
       "      <td>0.641670</td>\n",
       "      <td>-0.114203</td>\n",
       "      <td>-0.579018</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>-0.117485</td>\n",
       "      <td>-0.105816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244870</td>\n",
       "      <td>-0.647599</td>\n",
       "      <td>0.141032</td>\n",
       "      <td>0.058506</td>\n",
       "      <td>0.170133</td>\n",
       "      <td>0.120287</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.030734</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157803</th>\n",
       "      <td>110452.0</td>\n",
       "      <td>0.620212</td>\n",
       "      <td>0.164932</td>\n",
       "      <td>0.598195</td>\n",
       "      <td>-0.377247</td>\n",
       "      <td>-0.015231</td>\n",
       "      <td>0.592786</td>\n",
       "      <td>-0.711132</td>\n",
       "      <td>-0.720079</td>\n",
       "      <td>2.498107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712305</td>\n",
       "      <td>-0.092342</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>-0.039045</td>\n",
       "      <td>-0.292348</td>\n",
       "      <td>-0.539224</td>\n",
       "      <td>0.317870</td>\n",
       "      <td>0.360922</td>\n",
       "      <td>30.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "156961  109263.0  1.833227  0.364711  0.451166  4.091917 -0.227509  0.374196   \n",
       "179147  123946.0  2.085175  0.393051 -4.508201 -0.311771  3.510117  2.453299   \n",
       "15067    26414.0 -0.262444 -3.162121 -0.294218 -0.796267 -1.940072 -0.380838   \n",
       "23204    32637.0 -0.883467 -0.211395  1.359311 -1.221876  0.498644  0.080569   \n",
       "111394   72214.0  1.075827 -0.274463  1.093012  1.532927 -0.583176  1.082587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "222979  143204.0  2.239052 -1.468257 -0.415760 -1.651330 -1.518224 -0.328507   \n",
       "67355    52491.0  1.314442 -0.765168  0.119475 -0.787712 -0.501423  0.448607   \n",
       "166502  118117.0  0.146613  1.232617 -1.281238 -0.092007  0.962813 -0.449265   \n",
       "101600   67890.0  1.197949  0.343806  0.287047  0.641670 -0.114203 -0.579018   \n",
       "157803  110452.0  0.620212  0.164932  0.598195 -0.377247 -0.015231  0.592786   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "156961 -0.583237  0.023417  0.954938  ...  0.041577  0.485685  0.189123   \n",
       "179147  0.220469  0.543377 -0.100434  ... -0.067217 -0.072642 -0.036584   \n",
       "15067   0.388393 -0.228600  1.992874  ...  0.574583  0.075166 -0.887120   \n",
       "23204   1.007131 -0.109152 -0.354324  ... -0.099961 -0.615560  0.241685   \n",
       "111394 -0.733305  0.520508  1.189631  ... -0.403918 -0.757279  0.052991   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "222979 -1.458644  0.004632 -1.217365  ... -0.371511 -0.623488  0.412349   \n",
       "67355  -0.723523  0.170127 -0.630945  ...  0.017943  0.081010 -0.139929   \n",
       "166502  0.361553 -1.860332  0.161723  ...  1.471837 -0.374324 -0.377807   \n",
       "101600  0.079723 -0.117485 -0.105816  ... -0.244870 -0.647599  0.141032   \n",
       "157803 -0.711132 -0.720079  2.498107  ...  0.712305 -0.092342  0.052379   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "156961 -0.084402 -0.264453 -0.009945 -0.006484 -0.034535   18.96      0  \n",
       "179147  0.529693  0.414685  0.735870 -0.058233 -0.026658    0.76      0  \n",
       "15067  -0.008395  0.270159 -0.040588 -0.102476  0.160309  816.62      0  \n",
       "23204  -0.836969 -0.307358  0.594305 -0.218686 -0.112627  164.01      0  \n",
       "111394 -0.332710  0.403760 -0.502030  0.081161  0.011272    2.00      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "222979 -0.404534 -0.595912 -0.483846  0.034075 -0.047606   15.95      0  \n",
       "67355  -0.784148  0.550084 -0.182887  0.019586 -0.004491   36.28      0  \n",
       "166502 -0.846036  1.083432  0.829297  0.214370  0.285213   29.56      0  \n",
       "101600  0.058506  0.170133  0.120287 -0.002370  0.030734    9.99      0  \n",
       "157803 -0.039045 -0.292348 -0.539224  0.317870  0.360922   30.24      0  \n",
       "\n",
       "[492 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample_m = Non_fraudulent.sample(n=fraudulent.shape[0],random_state=3)\n",
    "undersample_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa4e31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541  -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920  0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108 -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329  1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating undersampled data non-fraudulent data with fradulent\n",
    "\n",
    "df_new= pd.concat([fraudulent, undersample_m], axis=0)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a2d967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirming if both have equal amount of classes within them\n",
    "df_new[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25d948",
   "metadata": {},
   "source": [
    "#### Comparison of class (Fraudulent and non Fraudulent) means before and after sampling to ensure minimal variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea1d402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.291022</td>\n",
       "      <td>95.142337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.211321</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Before       After\n",
       "Class                        \n",
       "0       88.291022   95.142337\n",
       "1      122.211321  122.211321"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Before\" : df.groupby(\"Class\")[\"Amount\"].mean(), \"After\": df_new.groupby(\"Class\")[\"Amount\"].mean()         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77f1e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so our sampling is good as we can see both means are same else resample\n",
    "#? is this a good way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53ddca",
   "metadata": {},
   "source": [
    "### Seperating Dependant and Independant Varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8a1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df_new.drop(columns=[\"Class\"])\n",
    "y= df_new[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96b7136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.75, stratify=y, random_state=1)\n",
    "#stratify makes sure that test data contains both the classes\n",
    "#random_state makes sure that there is reproducibility across all machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c01fc2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((738, 30), (738,), (246, 30), (246,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xtest.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fa6a9",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced3bc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d477a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       369\n",
      "           1       0.97      0.91      0.94       369\n",
      "\n",
      "    accuracy                           0.94       738\n",
      "   macro avg       0.94      0.94      0.94       738\n",
      "weighted avg       0.94      0.94      0.94       738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "ypredict= lr.predict(xtrain)\n",
    "print(classification_report(ytrain,ypredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "259fd87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       123\n",
      "           1       0.96      0.89      0.92       123\n",
      "\n",
      "    accuracy                           0.93       246\n",
      "   macro avg       0.93      0.93      0.93       246\n",
      "weighted avg       0.93      0.93      0.93       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "ypredict= lr.predict(xtest)\n",
    "print(classification_report(ytest,ypredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac364b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fbdb272",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e46e06",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1eff7",
   "metadata": {},
   "source": [
    "## Seperating Dependant and Independant Varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b32e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=\"Class\")\n",
    "y=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b95d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09cdd131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213605, 30), (71202, 30), (213605,), (71202,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,xtest.shape,ytrain.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3931bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()/df.shape[0] #orginal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c33f6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74.870351\n",
       "1     0.129561\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()/df.shape[0]*100 #ytrain class ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecf4b6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.956901\n",
       "1     0.043187\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()/df.shape[0]*100 #ytest class ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c732ad6",
   "metadata": {},
   "source": [
    "# Model : With Default Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b01a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a User defined function for for model validation so that we can avoid rewriting the code\n",
    "def model_validation(model,x_train,x_test,y_train,y_test):\n",
    "    global m\n",
    "    m=model\n",
    "    m.fit(x_train,y_train)\n",
    "    \n",
    "    print(\"\\033[1mTraining Metrics\\033[0m\")\n",
    "    ypred_train= m.predict(xtrain)\n",
    "    print(\"\\nConfusion Matrix \\n\",confusion_matrix(ytrain,ypred_train))\n",
    "    print(\"\\nClassification Report\",classification_report(ytrain,ypred_train))\n",
    "    \n",
    "    print(\"\\033[1m_________________________________________________________________________ \\n\")\n",
    "    \n",
    "    print(\"\\033[1mTesting Metrics\\033[0m\")\n",
    "    ypred_test= m.predict(xtest)\n",
    "    print(\"\\nConfusion Matrix \\n\",confusion_matrix(ytest,ypred_test))\n",
    "    print(\"\\nClassification Report\",classification_report(ytest,ypred_test))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3da22f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213149     87]\n",
      " [   156    213]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       0.71      0.58      0.64       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       0.85      0.79      0.82    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[71059    20]\n",
      " [   37    86]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.81      0.70      0.75       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.91      0.85      0.88     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(),xtrain,xtest,ytrain,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2750a",
   "metadata": {},
   "source": [
    "# Model : Appling Different ways to Remove Imbalance in  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ecb38",
   "metadata": {},
   "source": [
    "### Lets explore different sampling techniques:\n",
    "\n",
    " * Manually Random undersampling the data\n",
    " \n",
    " * Undersampling \n",
    " * Oversampling\n",
    " * SMOTE (Synthesis Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ce4c4",
   "metadata": {},
   "source": [
    "### Lets Try different ways to balance the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13962595",
   "metadata": {},
   "source": [
    "## METHOD 1:  Undersampling using Manual Method\n",
    "\n",
    "**Note you can use RandomUnderSampler from the imblearn.undersampling instead of this**. This is just to illustrate one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13723ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab10fcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraudulent= df[df[\"Class\"]==0]\n",
    "non_fraudulent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d88b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent= df[df[\"Class\"]==1]\n",
    "fraudulent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf951418",
   "metadata": {},
   "source": [
    "### Undersampling the ``non_fraudlent`` sample same as fraudulent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a4b6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>69808.0</td>\n",
       "      <td>0.136174</td>\n",
       "      <td>-1.647766</td>\n",
       "      <td>0.850033</td>\n",
       "      <td>1.576178</td>\n",
       "      <td>-1.569057</td>\n",
       "      <td>-0.106752</td>\n",
       "      <td>0.026632</td>\n",
       "      <td>-0.091738</td>\n",
       "      <td>0.517553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584649</td>\n",
       "      <td>0.582371</td>\n",
       "      <td>-0.548530</td>\n",
       "      <td>0.456719</td>\n",
       "      <td>0.202315</td>\n",
       "      <td>-0.314320</td>\n",
       "      <td>-0.018220</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>540.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102005</th>\n",
       "      <td>68015.0</td>\n",
       "      <td>-0.911610</td>\n",
       "      <td>0.680815</td>\n",
       "      <td>1.344329</td>\n",
       "      <td>-0.068517</td>\n",
       "      <td>0.596394</td>\n",
       "      <td>-1.268838</td>\n",
       "      <td>0.769226</td>\n",
       "      <td>-0.134888</td>\n",
       "      <td>-0.247848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139301</td>\n",
       "      <td>0.252879</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>0.360421</td>\n",
       "      <td>0.043382</td>\n",
       "      <td>-0.588531</td>\n",
       "      <td>-0.026174</td>\n",
       "      <td>0.159864</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278450</th>\n",
       "      <td>168231.0</td>\n",
       "      <td>-0.917299</td>\n",
       "      <td>0.860942</td>\n",
       "      <td>1.201170</td>\n",
       "      <td>-0.962314</td>\n",
       "      <td>-0.372495</td>\n",
       "      <td>-0.114847</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.699885</td>\n",
       "      <td>-0.040284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138630</td>\n",
       "      <td>-0.493530</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.370406</td>\n",
       "      <td>-0.392434</td>\n",
       "      <td>0.304997</td>\n",
       "      <td>0.177416</td>\n",
       "      <td>0.115137</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120218</th>\n",
       "      <td>75751.0</td>\n",
       "      <td>1.252596</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.044063</td>\n",
       "      <td>0.325909</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>-0.097035</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.263268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096153</td>\n",
       "      <td>-0.266459</td>\n",
       "      <td>-0.071237</td>\n",
       "      <td>-0.749998</td>\n",
       "      <td>0.389529</td>\n",
       "      <td>0.494047</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>17.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258527</th>\n",
       "      <td>158694.0</td>\n",
       "      <td>-1.109483</td>\n",
       "      <td>1.061341</td>\n",
       "      <td>1.484072</td>\n",
       "      <td>0.923891</td>\n",
       "      <td>-0.137718</td>\n",
       "      <td>0.816640</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>-0.125829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.479951</td>\n",
       "      <td>-1.369632</td>\n",
       "      <td>-0.020618</td>\n",
       "      <td>0.578319</td>\n",
       "      <td>0.329709</td>\n",
       "      <td>-0.825568</td>\n",
       "      <td>0.209439</td>\n",
       "      <td>0.068794</td>\n",
       "      <td>24.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26476</th>\n",
       "      <td>34090.0</td>\n",
       "      <td>1.384778</td>\n",
       "      <td>-0.613943</td>\n",
       "      <td>-0.473714</td>\n",
       "      <td>-1.080493</td>\n",
       "      <td>-0.134557</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>-0.322239</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>-1.099339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926508</td>\n",
       "      <td>-2.437317</td>\n",
       "      <td>0.107510</td>\n",
       "      <td>-1.453848</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>0.602221</td>\n",
       "      <td>-0.085445</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>55.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232704</th>\n",
       "      <td>147272.0</td>\n",
       "      <td>-0.662865</td>\n",
       "      <td>-0.063548</td>\n",
       "      <td>-0.453997</td>\n",
       "      <td>0.365725</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>-1.877818</td>\n",
       "      <td>1.369474</td>\n",
       "      <td>-0.415603</td>\n",
       "      <td>0.164133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319064</td>\n",
       "      <td>1.076870</td>\n",
       "      <td>0.572212</td>\n",
       "      <td>0.805659</td>\n",
       "      <td>-0.418046</td>\n",
       "      <td>-0.197208</td>\n",
       "      <td>0.118548</td>\n",
       "      <td>0.085739</td>\n",
       "      <td>173.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161997</th>\n",
       "      <td>114733.0</td>\n",
       "      <td>-1.072320</td>\n",
       "      <td>-1.383812</td>\n",
       "      <td>1.110494</td>\n",
       "      <td>-3.057725</td>\n",
       "      <td>0.355135</td>\n",
       "      <td>-0.062749</td>\n",
       "      <td>-0.135126</td>\n",
       "      <td>-0.519193</td>\n",
       "      <td>-1.626258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226405</td>\n",
       "      <td>0.265666</td>\n",
       "      <td>-0.437952</td>\n",
       "      <td>0.378339</td>\n",
       "      <td>-0.278275</td>\n",
       "      <td>-0.400838</td>\n",
       "      <td>-0.468408</td>\n",
       "      <td>-0.180677</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176374</th>\n",
       "      <td>122737.0</td>\n",
       "      <td>-0.580157</td>\n",
       "      <td>0.568520</td>\n",
       "      <td>2.000309</td>\n",
       "      <td>-0.551757</td>\n",
       "      <td>0.202593</td>\n",
       "      <td>0.304296</td>\n",
       "      <td>0.763987</td>\n",
       "      <td>-0.039123</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218156</td>\n",
       "      <td>-0.535974</td>\n",
       "      <td>-0.167347</td>\n",
       "      <td>0.548246</td>\n",
       "      <td>0.296848</td>\n",
       "      <td>-0.467760</td>\n",
       "      <td>-0.107231</td>\n",
       "      <td>-0.141449</td>\n",
       "      <td>49.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138224</th>\n",
       "      <td>82548.0</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>-0.650138</td>\n",
       "      <td>0.977318</td>\n",
       "      <td>1.154468</td>\n",
       "      <td>-0.388724</td>\n",
       "      <td>1.745749</td>\n",
       "      <td>-0.836021</td>\n",
       "      <td>0.724766</td>\n",
       "      <td>0.959928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161340</td>\n",
       "      <td>0.444720</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>-0.996731</td>\n",
       "      <td>-0.014749</td>\n",
       "      <td>-0.277953</td>\n",
       "      <td>0.110193</td>\n",
       "      <td>0.039860</td>\n",
       "      <td>116.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "106066   69808.0  0.136174 -1.647766  0.850033  1.576178 -1.569057 -0.106752   \n",
       "102005   68015.0 -0.911610  0.680815  1.344329 -0.068517  0.596394 -1.268838   \n",
       "278450  168231.0 -0.917299  0.860942  1.201170 -0.962314 -0.372495 -0.114847   \n",
       "120218   75751.0  1.252596  0.021359  0.044063  0.325909  0.011174 -0.053598   \n",
       "258527  158694.0 -1.109483  1.061341  1.484072  0.923891 -0.137718  0.816640   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "26476    34090.0  1.384778 -0.613943 -0.473714 -1.080493 -0.134557  0.127233   \n",
       "232704  147272.0 -0.662865 -0.063548 -0.453997  0.365725 -0.053082 -1.877818   \n",
       "161997  114733.0 -1.072320 -1.383812  1.110494 -3.057725  0.355135 -0.062749   \n",
       "176374  122737.0 -0.580157  0.568520  2.000309 -0.551757  0.202593  0.304296   \n",
       "138224   82548.0  0.766537 -0.650138  0.977318  1.154468 -0.388724  1.745749   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "106066  0.026632 -0.091738  0.517553  ...  0.584649  0.582371 -0.548530   \n",
       "102005  0.769226 -0.134888 -0.247848  ...  0.139301  0.252879 -0.228605   \n",
       "278450  0.001741  0.699885 -0.040284  ... -0.138630 -0.493530  0.001530   \n",
       "120218 -0.097035  0.013237  0.263268  ... -0.096153 -0.266459 -0.071237   \n",
       "258527  0.014252  0.938303 -0.125829  ... -0.479951 -1.369632 -0.020618   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "26476  -0.322239 -0.005842 -1.099339  ... -0.926508 -2.437317  0.107510   \n",
       "232704  1.369474 -0.415603  0.164133  ...  0.319064  1.076870  0.572212   \n",
       "161997 -0.135126 -0.519193 -1.626258  ... -0.226405  0.265666 -0.437952   \n",
       "176374  0.763987 -0.039123  0.280374  ... -0.218156 -0.535974 -0.167347   \n",
       "138224 -0.836021  0.724766  0.959928  ...  0.161340  0.444720  0.045154   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "106066  0.456719  0.202315 -0.314320 -0.018220  0.138062  540.00      0  \n",
       "102005  0.360421  0.043382 -0.588531 -0.026174  0.159864    6.89      0  \n",
       "278450 -0.370406 -0.392434  0.304997  0.177416  0.115137   19.99      0  \n",
       "120218 -0.749998  0.389529  0.494047 -0.029793  0.002433   17.80      0  \n",
       "258527  0.578319  0.329709 -0.825568  0.209439  0.068794   24.48      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "26476  -1.453848  0.010721  0.602221 -0.085445 -0.006771   55.90      0  \n",
       "232704  0.805659 -0.418046 -0.197208  0.118548  0.085739  173.05      0  \n",
       "161997  0.378339 -0.278275 -0.400838 -0.468408 -0.180677   88.00      0  \n",
       "176374  0.548246  0.296848 -0.467760 -0.107231 -0.141449   49.98      0  \n",
       "138224 -0.996731 -0.014749 -0.277953  0.110193  0.039860  116.49      0  \n",
       "\n",
       "[492 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_non_fraudulent=non_fraudulent.sample(fraudulent.shape[0],random_state=1)\n",
    "undersampled_non_fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "730575ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106066</th>\n",
       "      <td>69808.0</td>\n",
       "      <td>0.136174</td>\n",
       "      <td>-1.647766</td>\n",
       "      <td>0.850033</td>\n",
       "      <td>1.576178</td>\n",
       "      <td>-1.569057</td>\n",
       "      <td>-0.106752</td>\n",
       "      <td>0.026632</td>\n",
       "      <td>-0.091738</td>\n",
       "      <td>0.517553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584649</td>\n",
       "      <td>0.582371</td>\n",
       "      <td>-0.548530</td>\n",
       "      <td>0.456719</td>\n",
       "      <td>0.202315</td>\n",
       "      <td>-0.314320</td>\n",
       "      <td>-0.018220</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>540.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102005</th>\n",
       "      <td>68015.0</td>\n",
       "      <td>-0.911610</td>\n",
       "      <td>0.680815</td>\n",
       "      <td>1.344329</td>\n",
       "      <td>-0.068517</td>\n",
       "      <td>0.596394</td>\n",
       "      <td>-1.268838</td>\n",
       "      <td>0.769226</td>\n",
       "      <td>-0.134888</td>\n",
       "      <td>-0.247848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139301</td>\n",
       "      <td>0.252879</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>0.360421</td>\n",
       "      <td>0.043382</td>\n",
       "      <td>-0.588531</td>\n",
       "      <td>-0.026174</td>\n",
       "      <td>0.159864</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278450</th>\n",
       "      <td>168231.0</td>\n",
       "      <td>-0.917299</td>\n",
       "      <td>0.860942</td>\n",
       "      <td>1.201170</td>\n",
       "      <td>-0.962314</td>\n",
       "      <td>-0.372495</td>\n",
       "      <td>-0.114847</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.699885</td>\n",
       "      <td>-0.040284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138630</td>\n",
       "      <td>-0.493530</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.370406</td>\n",
       "      <td>-0.392434</td>\n",
       "      <td>0.304997</td>\n",
       "      <td>0.177416</td>\n",
       "      <td>0.115137</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120218</th>\n",
       "      <td>75751.0</td>\n",
       "      <td>1.252596</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.044063</td>\n",
       "      <td>0.325909</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>-0.097035</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.263268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096153</td>\n",
       "      <td>-0.266459</td>\n",
       "      <td>-0.071237</td>\n",
       "      <td>-0.749998</td>\n",
       "      <td>0.389529</td>\n",
       "      <td>0.494047</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>17.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258527</th>\n",
       "      <td>158694.0</td>\n",
       "      <td>-1.109483</td>\n",
       "      <td>1.061341</td>\n",
       "      <td>1.484072</td>\n",
       "      <td>0.923891</td>\n",
       "      <td>-0.137718</td>\n",
       "      <td>0.816640</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>-0.125829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.479951</td>\n",
       "      <td>-1.369632</td>\n",
       "      <td>-0.020618</td>\n",
       "      <td>0.578319</td>\n",
       "      <td>0.329709</td>\n",
       "      <td>-0.825568</td>\n",
       "      <td>0.209439</td>\n",
       "      <td>0.068794</td>\n",
       "      <td>24.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "106066   69808.0  0.136174 -1.647766  0.850033  1.576178 -1.569057 -0.106752   \n",
       "102005   68015.0 -0.911610  0.680815  1.344329 -0.068517  0.596394 -1.268838   \n",
       "278450  168231.0 -0.917299  0.860942  1.201170 -0.962314 -0.372495 -0.114847   \n",
       "120218   75751.0  1.252596  0.021359  0.044063  0.325909  0.011174 -0.053598   \n",
       "258527  158694.0 -1.109483  1.061341  1.484072  0.923891 -0.137718  0.816640   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "106066  0.026632 -0.091738  0.517553  ...  0.584649  0.582371 -0.548530   \n",
       "102005  0.769226 -0.134888 -0.247848  ...  0.139301  0.252879 -0.228605   \n",
       "278450  0.001741  0.699885 -0.040284  ... -0.138630 -0.493530  0.001530   \n",
       "120218 -0.097035  0.013237  0.263268  ... -0.096153 -0.266459 -0.071237   \n",
       "258527  0.014252  0.938303 -0.125829  ... -0.479951 -1.369632 -0.020618   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "106066  0.456719  0.202315 -0.314320 -0.018220  0.138062  540.00      0  \n",
       "102005  0.360421  0.043382 -0.588531 -0.026174  0.159864    6.89      0  \n",
       "278450 -0.370406 -0.392434  0.304997  0.177416  0.115137   19.99      0  \n",
       "120218 -0.749998  0.389529  0.494047 -0.029793  0.002433   17.80      0  \n",
       "258527  0.578319  0.329709 -0.825568  0.209439  0.068794   24.48      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new= pd.concat([undersampled_non_fraudulent,fraudulent],axis=0) #default axis =0\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a341f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8681b180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    492\n",
       "1    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a5d67",
   "metadata": {},
   "source": [
    "***Separating the features (X) and the target variable (Y), followed by splitting the data into training and testing sets for Method 1 only***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98dae608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m1=df_new.drop(columns=\"Class\")\n",
    "y_m1= df_new[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92c2fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((984, 30), (984,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_m1.shape,y_m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdb86618",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_m1,xtest_m1,ytrain_m1,ytest_m1 = train_test_split(x_m1,y_m1,train_size=0.8,stratify=y_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0dee1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((787, 30), (197, 30), (787,), (197,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_m1.shape,xtest_m1.shape,ytrain_m1.shape,ytest_m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09b6cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[202303  10933]\n",
      " [    28    341]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    213236\n",
      "           1       0.03      0.92      0.06       369\n",
      "\n",
      "    accuracy                           0.95    213605\n",
      "   macro avg       0.52      0.94      0.52    213605\n",
      "weighted avg       1.00      0.95      0.97    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[67540  3539]\n",
      " [    8   115]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     71079\n",
      "           1       0.03      0.93      0.06       123\n",
      "\n",
      "    accuracy                           0.95     71202\n",
      "   macro avg       0.52      0.94      0.52     71202\n",
      "weighted avg       1.00      0.95      0.97     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(),xtrain_m1,xtest_m1,ytrain_m1,ytest_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00aa14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed0b6e69",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd0df6",
   "metadata": {},
   "source": [
    "#### Note here onwards we can going to the acutal xtrain,xtest ytrain, ytest data, not the one we used in the Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f4ee5",
   "metadata": {},
   "source": [
    "## METHOD 2: Undersampling - RandomUnderSample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96214f9e",
   "metadata": {},
   "source": [
    "RandomUnderSampler(\n",
    "    *,\n",
    "    sampling_strategy='auto',\n",
    "    random_state=None,\n",
    "    replacement=False,\n",
    ")\n",
    "\n",
    "**sampling_strategy :**\n",
    "\n",
    "- When ``float``, it corresponds to the desired ratio of the number of samples in the minority class over the number of samples in the majority class after resampling. Therefore, the ratio is expressed as\n",
    "\n",
    "\n",
    " **- ``float`` is only available for binary classification. An error is raised for multi-class classification.**\n",
    "\n",
    "\n",
    "- When ``str``, specify the class targeted by the resampling. The\n",
    "      number of samples in the different classes will be equalized.\n",
    "      Possible choices are:\n",
    "\n",
    "   * ``'minority'``: resample only the minority class;\n",
    "\n",
    "   *        ``'not minority'``: resample all classes but the minority class;\n",
    "\n",
    "   *    ``'not majority'``: resample all classes but the majority class;\n",
    "\n",
    "   *    ``'all'``: resample all classes;\n",
    "\n",
    "   *    ``'auto'``: equivalent to ``'not majority'.\n",
    "   \n",
    "   \n",
    "\n",
    "**replacement:**\n",
    "\n",
    "    bool, default=False\n",
    "    Whether the sample is with or without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2de504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4ad6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ce634f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b, ytrain_b = undersampling.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a45286cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1       369\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts() #orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2c486ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    369\n",
       "1    369\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_b.value_counts() #after undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab337414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[204646   8590]\n",
      " [    31    338]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    213236\n",
      "           1       0.04      0.92      0.07       369\n",
      "\n",
      "    accuracy                           0.96    213605\n",
      "   macro avg       0.52      0.94      0.53    213605\n",
      "weighted avg       1.00      0.96      0.98    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[68233  2846]\n",
      " [    6   117]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     71079\n",
      "           1       0.04      0.95      0.08       123\n",
      "\n",
      "    accuracy                           0.96     71202\n",
      "   macro avg       0.52      0.96      0.53     71202\n",
      "weighted avg       1.00      0.96      0.98     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(),xtrain_b, xtest,ytrain_b, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cfd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc6e6e82",
   "metadata": {},
   "source": [
    "## METHOD 3:  Oversampling - RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e1f40",
   "metadata": {},
   "source": [
    "RandomOverSampler(*,\n",
    "* sampling_strategy='auto',\n",
    "* random_state=None,\n",
    "* shrinkage=None)\n",
    "\n",
    "**sampling_strategy :**\n",
    "\n",
    "- When ``float``, it corresponds to the desired ratio of the number of samples in the minority class over the number of samples in the majority class after resampling. Therefore, the ratio is expressed as\n",
    "\n",
    "\n",
    " **- ``float`` is only available for binary classification. An error is raised for multi-class classification.**\n",
    "\n",
    "\n",
    "- When ``str``, specify the class targeted by the resampling. The\n",
    "      number of samples in the different classes will be equalized.\n",
    "      Possible choices are:\n",
    "\n",
    "   * ``'minority'``: resample only the minority class;\n",
    "\n",
    "   *        ``'not minority'``: resample all classes but the minority class;\n",
    "\n",
    "   *    ``'not majority'``: resample all classes but the majority class;\n",
    "\n",
    "   *    ``'all'``: resample all classes;\n",
    "\n",
    "   *    ``'auto'``: equivalent to ``'not majority'.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "731a9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a807def",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_oversampling= RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dde7f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b,ytrain_b=random_oversampling.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e6c04a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1       369\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts() #orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f55680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1    213236\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_b.value_counts() #after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13603e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[205193   8043]\n",
      " [    35    334]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    213236\n",
      "           1       0.04      0.91      0.08       369\n",
      "\n",
      "    accuracy                           0.96    213605\n",
      "   macro avg       0.52      0.93      0.53    213605\n",
      "weighted avg       1.00      0.96      0.98    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[68425  2654]\n",
      " [    9   114]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     71079\n",
      "           1       0.04      0.93      0.08       123\n",
      "\n",
      "    accuracy                           0.96     71202\n",
      "   macro avg       0.52      0.94      0.53     71202\n",
      "weighted avg       1.00      0.96      0.98     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(),xtrain_b, xtest,ytrain_b, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7869838",
   "metadata": {},
   "source": [
    "## METHOD 4:  SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "416ea92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a678d",
   "metadata": {},
   "source": [
    "SMOTE(\n",
    "    *,\n",
    "    sampling_strategy='auto',\n",
    "    random_state=None,\n",
    "    k_neighbors=5,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "\n",
    "**sampling_strategy :**\n",
    "\n",
    "\n",
    "- When ``float``, it corresponds to the desired ratio of the number of samples in the minority class over the number of samples in the majority class after resampling. Therefore, the ratio is expressed as\n",
    "\n",
    "\n",
    " **- ``float`` is only available for binary classification. An error is raised for multi-class classification.**\n",
    "\n",
    "\n",
    "- When ``str``, specify the class targeted by the resampling. The\n",
    "      number of samples in the different classes will be equalized.\n",
    "      Possible choices are:\n",
    "\n",
    "   * ``'minority'``: resample only the minority class;\n",
    "\n",
    "   *        ``'not minority'``: resample all classes but the minority class;\n",
    "\n",
    "   *    ``'not majority'``: resample all classes but the majority class;\n",
    "\n",
    "   *    ``'all'``: resample all classes;\n",
    "\n",
    "   *    ``'auto'``: equivalent to ``'not majority'.\n",
    "   \n",
    "   \n",
    "**k_neighbors :** \n",
    "\n",
    "    int or object, default=5\n",
    "    The nearest neighbors used to define the neighborhood of samples to use\n",
    "    to generate the synthetic samples\n",
    "    \n",
    "    \n",
    "**n_jobs :**\n",
    "\n",
    "    int, default=None\n",
    "    Number of CPU cores used during the cross-validation loop.\n",
    "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "    ``-1`` means using all processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ae3b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto') #default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f794a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b , ytrain_b = smote.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b22bc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1       369\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts() #orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b3c908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1    213236\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_b.value_counts() #after smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a640705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[209335   3901]\n",
      " [    41    328]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    213236\n",
      "           1       0.08      0.89      0.14       369\n",
      "\n",
      "    accuracy                           0.98    213605\n",
      "   macro avg       0.54      0.94      0.57    213605\n",
      "weighted avg       1.00      0.98      0.99    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[69809  1270]\n",
      " [   11   112]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71079\n",
      "           1       0.08      0.91      0.15       123\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.54      0.95      0.57     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57643e",
   "metadata": {},
   "source": [
    "***Trying Smote sampling stratergy  as 0.7 (make minority class  70% of the majority class)***\n",
    "\n",
    "***Note this works only with binary classification , not for mulit-class classifiaction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b5ca54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote= SMOTE(sampling_strategy=0.7)  # note you can do this in RandomOversampler and RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3d80b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b,ytrain_b = smote.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33ca7463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1       369\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts() #orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8da49f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    213236\n",
       "1    149265\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_b.value_counts() #after smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bec973",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e9cb360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[209551   3685]\n",
      " [    43    326]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    213236\n",
      "           1       0.08      0.88      0.15       369\n",
      "\n",
      "    accuracy                           0.98    213605\n",
      "   macro avg       0.54      0.93      0.57    213605\n",
      "weighted avg       1.00      0.98      0.99    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[69876  1203]\n",
      " [   10   113]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71079\n",
      "           1       0.09      0.92      0.16       123\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.54      0.95      0.57     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(LogisticRegression(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbb85d",
   "metadata": {},
   "source": [
    "# Trying More Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e613e8b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ca99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf236995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[206385   6851]\n",
      " [     1    368]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    213236\n",
      "           1       0.05      1.00      0.10       369\n",
      "\n",
      "    accuracy                           0.97    213605\n",
      "   macro avg       0.53      0.98      0.54    213605\n",
      "weighted avg       1.00      0.97      0.98    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[67677  3402]\n",
      " [   59    64]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     71079\n",
      "           1       0.02      0.52      0.04       123\n",
      "\n",
      "    accuracy                           0.95     71202\n",
      "   macro avg       0.51      0.74      0.51     71202\n",
      "weighted avg       1.00      0.95      0.97     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(KNeighborsClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046ef61",
   "metadata": {},
   "source": [
    "## Niave Baye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ebb7aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes is a classification algorithm based on Bayes' theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3db13",
   "metadata": {},
   "source": [
    " GaussianNB(*, \n",
    "   priors=None,\n",
    "   var_smoothing=1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01ee0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "#GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b742e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[211645   1591]\n",
      " [    97    272]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    213236\n",
      "           1       0.15      0.74      0.24       369\n",
      "\n",
      "    accuracy                           0.99    213605\n",
      "   macro avg       0.57      0.86      0.62    213605\n",
      "weighted avg       1.00      0.99      0.99    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[70535   544]\n",
      " [   20   103]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     71079\n",
      "           1       0.16      0.84      0.27       123\n",
      "\n",
      "    accuracy                           0.99     71202\n",
      "   macro avg       0.58      0.91      0.63     71202\n",
      "weighted avg       1.00      0.99      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(GaussianNB(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5faacc",
   "metadata": {},
   "source": [
    "## Decsion Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8f72b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bf83f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213236      0]\n",
      " [     0    369]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       1.00      1.00      1.00    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[70924   155]\n",
      " [   15   108]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.41      0.88      0.56       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.71      0.94      0.78     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(DecisionTreeClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0f95a",
   "metadata": {},
   "source": [
    "## Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f058045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50c17743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213236      0]\n",
      " [     0    369]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       1.00      1.00      1.00    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[71066    13]\n",
      " [   14   109]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.89      0.89      0.89       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.95      0.94      0.94     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(RandomForestClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92161b49",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ca14b",
   "metadata": {},
   "source": [
    "BaggingClassifier(\n",
    "    \n",
    "    estimator=None,\n",
    "    n_estimators=10,\n",
    "    *,\n",
    "    max_samples=1.0,\n",
    "    max_features=1.0,\n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=False,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "**The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a DecisionTreeClassifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52979096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5e7f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[206385   6851]\n",
      " [     1    368]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    213236\n",
      "           1       0.05      1.00      0.10       369\n",
      "\n",
      "    accuracy                           0.97    213605\n",
      "   macro avg       0.53      0.98      0.54    213605\n",
      "weighted avg       1.00      0.97      0.98    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[67677  3402]\n",
      " [   59    64]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     71079\n",
      "           1       0.02      0.52      0.04       123\n",
      "\n",
      "    accuracy                           0.95     71202\n",
      "   macro avg       0.51      0.74      0.51     71202\n",
      "weighted avg       1.00      0.95      0.97     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(BaggingClassifier(estimator=KNeighborsClassifier()), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae375076",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6e31a",
   "metadata": {},
   "source": [
    "## AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "618263ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e60d6708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[211068   2168]\n",
      " [    40    329]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    213236\n",
      "           1       0.13      0.89      0.23       369\n",
      "\n",
      "    accuracy                           0.99    213605\n",
      "   macro avg       0.57      0.94      0.61    213605\n",
      "weighted avg       1.00      0.99      0.99    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[70337   742]\n",
      " [   12   111]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     71079\n",
      "           1       0.13      0.90      0.23       123\n",
      "\n",
      "    accuracy                           0.99     71202\n",
      "   macro avg       0.56      0.95      0.61     71202\n",
      "weighted avg       1.00      0.99      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(AdaBoostClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04968df9",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57a0d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d71ee2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[212296    940]\n",
      " [    33    336]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       0.26      0.91      0.41       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       0.63      0.95      0.70    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[70767   312]\n",
      " [   11   112]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.26      0.91      0.41       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.63      0.95      0.70     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(GradientBoostingClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915016ab",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6aa3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6fab322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213236      0]\n",
      " [     0    369]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       1.00      1.00      1.00    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[71064    15]\n",
      " [   15   108]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.88      0.88      0.88       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.94      0.94      0.94     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(XGBClassifier(), xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a5c22",
   "metadata": {},
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40e68928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fcd51",
   "metadata": {},
   "source": [
    "StackingClassifier(\n",
    "\n",
    "    estimators,\n",
    "    final_estimator=None,\n",
    "    *,\n",
    "    cv=None,\n",
    "    stack_method='auto',\n",
    "    n_jobs=None,\n",
    "    passthrough=False,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "\n",
    "estimators : list of (str, estimator)\n",
    "    Base estimators which will be stacked together. Each element of the\n",
    "    list is defined as a tuple of string (i.e. name) and an estimator\n",
    "    instance. An estimator can be set to 'drop' using `set_params`.\n",
    "\n",
    "    The type of estimator is generally expected to be a classifier.\n",
    "    However, one can pass a regressor for some use case (e.g. ordinal\n",
    "    regression).\n",
    "\n",
    "final_estimator : estimator, default=None\n",
    "    A classifier which will be used to combine the base estimators.\n",
    "    \n",
    "   **The default classifier is a:class:`~sklearn.linear_model.LogisticRegression`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "751914fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models= [ (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n",
    "                (\"KNeighborsClassifier\",KNeighborsClassifier()),\n",
    "              (\"Naive Bayes\", GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ba6c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213236      0]\n",
      " [     0    369]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       1.00      1.00      1.00    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[70922   157]\n",
      " [   14   109]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.41      0.89      0.56       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.70      0.94      0.78     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(StackingClassifier(estimators=base_models, final_estimator=LogisticRegression()), \n",
    "                 xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4360f",
   "metadata": {},
   "source": [
    "## Votting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f390a",
   "metadata": {},
   "source": [
    "VotingClassifier(\n",
    "\n",
    "    estimators,\n",
    "    *,\n",
    "    voting='hard',\n",
    "    weights=None,\n",
    "    n_jobs=None,\n",
    "    flatten_transform=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4f41b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a1d6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models= [ (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n",
    "                (\"KNeighborsClassifier\",KNeighborsClassifier()),\n",
    "              (\"Naive Bayes\", GaussianNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d92b4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[213152     84]\n",
      " [     1    368]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    213236\n",
      "           1       0.81      1.00      0.90       369\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       0.91      1.00      0.95    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "\u001b[1m_________________________________________________________________________ \n",
      "\n",
      "\u001b[1mTesting Metrics\u001b[0m\n",
      "\n",
      "Confusion Matrix \n",
      " [[71019    60]\n",
      " [   17   106]]\n",
      "\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.64      0.86      0.73       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.82      0.93      0.87     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_validation(VotingClassifier(estimators=base_models), \n",
    "                 xtrain_b,xtest,ytrain_b,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904e8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37929b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cbc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f69ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce860ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0da667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957f066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b18614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b851cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2de2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d6c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d351f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d8d2848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,1,1)\n",
    "sns.boxplot(data=fraudulent, x=\"Amount\")\n",
    "plt.title(\"Fraudulent Transcation\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.boxplot(data=Non_fraudulent, x=\"Amount\")\n",
    "plt.title(\"Non Fraudulent Transcation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
